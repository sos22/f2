/* Client half of the event queue system.  The main guarantee an event
 * queue gives to its caller is that events are never dropped
 * silently: if the client connects at time A, the server generates an
 * event at time B and the client checks for events at time C, then
 * provided B is after A and C is sufficiently after B, C will either
 * receive the event or will receive an error indication.  The exact
 * meaning of ``sufficiently after'' is left unspecificied, beyond
 * specifying that the delay always be finite.  Note that the queue
 * can occasionally generate spurious errors, even when no events have
 * been dropped and there have been no ``actual'' errors, although we
 * obviously try to keep spurious errors sufficently rare not to
 * render the queue completely useless. */
#ifndef EQCLIENT_H__
#define EQCLIENT_H__

#include "buffer.H"
#include "clientio.H"
#include "eq.H"
#include "maybe.H"
#include "pubsub.H"
#include "serialise.H"
#include "timedelta.H"
#include "timestamp.H"

class connpool;
template <typename> class nnp;
template <typename> class orerror;
class slavename;
namespace tests { template <typename, typename...> class hookpoint; }

class eqclientconfig {
private: eqclientconfig();
    /* How long to wait for the server to respond to unsubscribe
     * messages before we just give up and shut down anyway.  It
     * should usually be short; seconds at most. */
public:  timedelta unsubscribe;
    /* Timeout on get requests before we conclude that the queue has
     * died and indicate an error to the higher levels.  This is the
     * minimum time the server must be uncontactable for before we
     * give up; the maximum is this plus the wait time.  This should
     * usually be on the order of a few seconds. */
public:  timedelta get;
    /* Timeout on wait requests before we give up and switch to
     * running get again.  Setting a short timeout here will allow us
     * to detect dead servers more quickly but will increase the
     * number of messages we need to send.  This should usually be on
     * the order of a minute or so. */
public:  timedelta wait;
    /* Maximum number of events to queue up on the client side (in
     * addition to the queue maintained on the server side).  This is
     * there to cover the gap between the queue thread receiving an
     * event and something higher up picking it up.  Making it too
     * small risks unnecessarily dropping events; making it too big
     * wastes memory and risks buffer bloat-like problems by making it
     * harder to detect when the client is overloaded.  Something on
     * the order of a few hundred is usually reasonable.  Less than
     * two will cause unpredictable behaviour. */
public:  unsigned maxqueue;
    /* Generate a reasonable default configuration. */
public:  static eqclientconfig dflt(); };

/* Implementation detail of eqclient. */
class geneqclient {
private: class impl;
    friend class impl;
public:  impl &implementation();
private: const impl &implementation() const;
public:  void start(clientio);
public:  static orerror<nnp<geneqclient> > connect(
    clientio io,
    connpool &pool,
    const slavename &sn,
    const proto::eq::genname &,
    timestamp deadline,
    const eqclientconfig &config);
public:  class asyncconnect {
    public:  class impl;
        friend class impl;
    public:  impl &implementation();
    public:  const impl &implementation() const;
    public:  const publisher &pub() const;
    public:  maybe<orerror<nnp<geneqclient> > > pop();
    public:  void abort(); };
public:  static nnp<asyncconnect> connect(
    connpool &pool,
    const slavename &sn,
    const proto::eq::genname &,
    const eqclientconfig &);
public:  const publisher &pub() const;
public:  maybe<orerror<buffer> > pop();
public:  void destroy(clientio);
private: ~geneqclient();
public:  static tests::hookpoint<void> startingwaiter; };

template <typename t> class eqclient final : private geneqclient {
private: eqclient();

    /* Note that this cannot have any members, because its destructor
     * is never invoked. */

    /* ``Connect'' to a remote event queue.  The semi-reliability
     * guarantee only applies to events generated by the server after
     * this returns.  This always succeeds; errors are reported at the
     * first call to pop(). */
public:  static orerror<nnp<eqclient> > connect(
    clientio io,
    connpool &pool,
    const slavename &sn,
    const proto::eq::name<t> &queue,
    timestamp d,
    const eqclientconfig &config = eqclientconfig::dflt()) {
        auto r(geneqclient::connect(io, pool, sn, queue, d, config));
        if (r.isfailure()) return r.failure();
        else return _nnp(*static_cast<eqclient *>(&*r.success())); }

    /* Async connect interface.  Start connecting to a remote queue,
     * but rather than waiting return an asyncconnect structure which
     * can be used to collect the results later. */
public:  class asyncconnect : private geneqclient::asyncconnect {
    private: asyncconnect(const asyncconnect &) = delete;
    private: void operator=(const asyncconnect &) = delete;
        /* Use connect() */
    private: asyncconnect();
        /* Use pop() or abort() */
    private: ~asyncconnect();
        /* Notified when pop() becomes non-Nothing. */
    public:  const publisher &pub() const {
        return geneqclient::asyncconnect::pub(); }
        /* If the connection has completed, return the queue and
         * destroy the the asyncconnect structure.  If it failed,
         * return the error and destroy the asyncconnect structure.
         * If it's still pending, return Nothing. */
public:  maybe<orerror<nnp<eqclient> > > pop() {
        auto r(geneqclient::asyncconnect::pop());
        if (r == Nothing) return Nothing;
        else if (r.just().isfailure()) {
            return orerror<nnp<eqclient> >(r.just().failure()); }
        else {
            auto &underlying(*r.just().success());
            return orerror<nnp<eqclient> >(
                _nnp(*static_cast<eqclient *>(&underlying))); } }
        /* Give up trying to connect to the queue and destroy the
         * asyncconnect. */
    public:  void abort() { geneqclient::asyncconnect::abort(); } };
public:  static nnp<asyncconnect> connect(
    connpool &pool,
    const slavename &sn,
    const proto::eq::name<t> &queue,
    const eqclientconfig &config = eqclientconfig::dflt()) {
        return _nnp(*reinterpret_cast<asyncconnect *>(
                        &*geneqclient::connect(pool, sn, queue, config))); }

    /* Notified whenever pop() becomes non-Nothing. */
public:  const publisher &pub() const { return geneqclient::pub(); }

    /* Extract the next thing from the queue, without blocking, and
     * return Nothing if nothing is currently available.  Can also
     * return an error if the queue has failed.  Errors are sticky:
     * the only way to clear them is to tear the queue down and start
     * again. */
public:  maybe<orerror<t> > pop() {
        auto r(geneqclient::pop());
        if (r == Nothing) return Nothing;
        else if (r.just().isfailure()) {
            return maybe<orerror<t> >(r.just().failure()); }
        else {
            deserialise1 ds(r.just().success());
            t res(ds);
            if (ds.isfailure()) return orerror<t>(ds.failure());
            else return success(res); } }

    /* Blocking variant of pop().  Equivalent to calling pop()
     * repeatedly until it returns non-Nothing. */
public:  orerror<t> pop(clientio io) {
        maybe<orerror<t> > res(pop());
        if (res == Nothing) {
            subscriber sub;
            subscription ss(sub, pub());
            res = pop();
            while (res == Nothing) {
                sub.wait(io);
                res = pop(); } }
        return res.just(); }

    /* Tear down a queue client, discarding any pending events not yet
     * returned by pop(). */
public:  void destroy(clientio io) { geneqclient::destroy(io); }

    /* Never actually called: base class destructor is non-virtual. */
private: ~eqclient() = delete; };

#endif /* !EQCLIENT_H__ */
